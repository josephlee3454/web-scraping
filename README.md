# Author: Joseph Lee
* 17 may 2020
* git hub
# Visit GitHub!.
* resources: stack overflow 
# overveiw
* web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis. 
# feature tasks
* Scrape a Wikipedia page and record which passages need citations.
* E.g. History of Mexico has 7 “citation needed” cases, as of this writing.
* Your web scraper should report the number of citations needed.
* Your web scraper should identify those cases AND include the relevant passage.
* E.g. Citation needed for “lorem spam and impsum eggs”
* Consider the “relevant passage” to be the parent element that contains the passage, often a paragraph element.
# Dependencies
* poetry
* python
* pyenv
# Authors
* software developer: Joseph Lee
* Official application github
* license
* This project is under the MIT License.